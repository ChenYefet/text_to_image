# ──────────────────────────────────────────────────────────────────────────────
# Text-to-Image with Prompt Assist — Environment Configuration
# ──────────────────────────────────────────────────────────────────────────────
# Copy this file to .env and adjust the values to match your local environment.
# All variables are prefixed with TEXT_TO_IMAGE_ to avoid collisions.
# ──────────────────────────────────────────────────────────────────────────────

# Base URL of the llama.cpp server running in OpenAI-compatible mode.
TEXT_TO_IMAGE_LANGUAGE_MODEL_SERVER_BASE_URL=http://localhost:8080

# HuggingFace model ID or local path for the Stable Diffusion model.
# The model is downloaded automatically from HuggingFace Hub on first run.
TEXT_TO_IMAGE_STABLE_DIFFUSION_MODEL_ID=stable-diffusion-v1-5/stable-diffusion-v1-5

# Device for Stable Diffusion inference: "auto", "cpu", or "cuda".
# "auto" selects CUDA when available, otherwise falls back to CPU.
TEXT_TO_IMAGE_STABLE_DIFFUSION_DEVICE=auto

# Host address on which this API service will listen.
TEXT_TO_IMAGE_APPLICATION_HOST=0.0.0.0

# Port on which this API service will listen.
TEXT_TO_IMAGE_APPLICATION_PORT=8000

# Maximum number of seconds to wait for a response from the language model server.
TEXT_TO_IMAGE_LANGUAGE_MODEL_REQUEST_TIMEOUT_SECONDS=120.0
