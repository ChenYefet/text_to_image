# ──────────────────────────────────────────────────────────────────────────────
# Text-to-Image with Prompt Assist — Environment Configuration
# ──────────────────────────────────────────────────────────────────────────────
# Copy this file to .env and adjust the values to match your local environment.
# All variables are prefixed with TEXT_TO_IMAGE_ to avoid collisions.
# ──────────────────────────────────────────────────────────────────────────────

# Base URL of the llama.cpp server running in OpenAI-compatible mode.
TEXT_TO_IMAGE_LANGUAGE_MODEL_SERVER_BASE_URL=http://localhost:8080

# Optional: Path to your GGUF model file. Not used at runtime — serves as a
# convenient reference for the --model argument passed to llama.cpp.
#   Windows default:    C:\Models\Meta-Llama-3-8B-Instruct.Q4_K_M.gguf
#   Linux/macOS default: ~/Models/Meta-Llama-3-8B-Instruct.Q4_K_M.gguf
TEXT_TO_IMAGE_LANGUAGE_MODEL_PATH=

# HuggingFace model ID or local path for the Stable Diffusion model.
# The model is downloaded automatically from HuggingFace Hub on first run.
TEXT_TO_IMAGE_STABLE_DIFFUSION_MODEL_ID=stable-diffusion-v1-5/stable-diffusion-v1-5

# Device for Stable Diffusion inference: "auto", "cpu", or "cuda".
# "auto" selects CUDA when available, otherwise falls back to CPU.
TEXT_TO_IMAGE_STABLE_DIFFUSION_DEVICE=auto

# Host address on which this API service will listen.
# Use 0.0.0.0 to expose the service on all network interfaces.
TEXT_TO_IMAGE_APPLICATION_HOST=127.0.0.1

# Port on which this API service will listen.
TEXT_TO_IMAGE_APPLICATION_PORT=8000

# Maximum number of seconds to wait for a response from the language model server.
TEXT_TO_IMAGE_LANGUAGE_MODEL_REQUEST_TIMEOUT_SECONDS=120.0

# Comma-separated list of allowed CORS origins.
# Leave empty to disable CORS (no Access-Control-Allow-Origin header).
# Example: http://localhost:3000,https://myapp.example.com
TEXT_TO_IMAGE_CORS_ALLOWED_ORIGINS=[]

# Enable the Stable Diffusion NSFW safety checker (true/false).
# Disabling it removes content filtering from generated images.
TEXT_TO_IMAGE_STABLE_DIFFUSION_SAFETY_CHECKER=true

# Log level for structured JSON logging: DEBUG, INFO, WARNING, ERROR, CRITICAL.
TEXT_TO_IMAGE_LOG_LEVEL=INFO

# Sampling temperature for prompt enhancement (0.0 = deterministic, higher = more creative).
TEXT_TO_IMAGE_LANGUAGE_MODEL_TEMPERATURE=0.7

# Maximum number of tokens the language model may generate for an enhanced prompt.
TEXT_TO_IMAGE_LANGUAGE_MODEL_MAX_TOKENS=512

# Number of denoising steps for Stable Diffusion inference.
# Higher values produce better quality but take longer.
TEXT_TO_IMAGE_STABLE_DIFFUSION_INFERENCE_STEPS=20

# Classifier-free guidance scale for Stable Diffusion.
# Higher values follow the prompt more closely; lower values are more creative.
TEXT_TO_IMAGE_STABLE_DIFFUSION_GUIDANCE_SCALE=7.0
